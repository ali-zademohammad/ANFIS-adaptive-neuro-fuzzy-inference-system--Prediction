{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANFIS pytorch for Viscosity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 47789.8984375\n",
      "Epoch 100, Loss: 4710.3818359375\n",
      "Epoch 200, Loss: 832.4027099609375\n",
      "Epoch 300, Loss: 355.44500732421875\n",
      "Epoch 400, Loss: 216.6623077392578\n",
      "Epoch 500, Loss: 194.5498504638672\n",
      "Epoch 600, Loss: 192.62339782714844\n",
      "Epoch 700, Loss: 192.03756713867188\n",
      "Epoch 800, Loss: 191.3979949951172\n",
      "Epoch 900, Loss: 190.59402465820312\n",
      "Epoch 1000, Loss: 189.5292205810547\n",
      "Epoch 1100, Loss: 187.9969024658203\n",
      "Epoch 1200, Loss: 185.44677734375\n",
      "Epoch 1300, Loss: 179.8091583251953\n",
      "Epoch 1400, Loss: 154.840576171875\n",
      "Epoch 1500, Loss: 67.85276794433594\n",
      "Epoch 1600, Loss: 54.515594482421875\n",
      "Epoch 1700, Loss: 49.842689514160156\n",
      "Epoch 1800, Loss: 41.822364807128906\n",
      "Epoch 1900, Loss: 30.094959259033203\n",
      "Epoch 2000, Loss: 28.763973236083984\n",
      "Epoch 2100, Loss: 28.422657012939453\n",
      "Epoch 2200, Loss: 28.12188720703125\n",
      "Epoch 2300, Loss: 27.800683975219727\n",
      "Epoch 2400, Loss: 27.451183319091797\n",
      "Epoch 2500, Loss: 27.06967544555664\n",
      "Epoch 2600, Loss: 26.652673721313477\n",
      "Epoch 2700, Loss: 26.195825576782227\n",
      "Epoch 2800, Loss: 25.69464111328125\n",
      "Epoch 2900, Loss: 25.143795013427734\n",
      "Epoch 3000, Loss: 24.537128448486328\n",
      "Epoch 3100, Loss: 23.868175506591797\n",
      "Epoch 3200, Loss: 23.13016700744629\n",
      "Epoch 3300, Loss: 22.31639862060547\n",
      "Epoch 3400, Loss: 21.420637130737305\n",
      "Epoch 3500, Loss: 20.438711166381836\n",
      "Epoch 3600, Loss: 19.37057876586914\n",
      "Epoch 3700, Loss: 18.221179962158203\n",
      "Epoch 3800, Loss: 17.00293731689453\n",
      "Epoch 3900, Loss: 15.735475540161133\n",
      "Epoch 4000, Loss: 14.44391918182373\n",
      "Epoch 4100, Loss: 13.15485668182373\n",
      "Epoch 4200, Loss: 11.893633842468262\n",
      "Epoch 4300, Loss: 10.681665420532227\n",
      "Epoch 4400, Loss: 9.535017967224121\n",
      "Epoch 4500, Loss: 8.464845657348633\n",
      "Epoch 4600, Loss: 7.479116916656494\n",
      "Epoch 4700, Loss: 6.580927848815918\n",
      "Epoch 4800, Loss: 5.771395206451416\n",
      "Epoch 4900, Loss: 5.048929691314697\n",
      "Epoch 5000, Loss: 4.410317420959473\n",
      "Epoch 5100, Loss: 3.851086139678955\n",
      "Epoch 5200, Loss: 3.365449905395508\n",
      "Epoch 5300, Loss: 2.947126865386963\n",
      "Epoch 5400, Loss: 2.5891871452331543\n",
      "Epoch 5500, Loss: 2.284658193588257\n",
      "Epoch 5600, Loss: 2.026419162750244\n",
      "Epoch 5700, Loss: 1.8078876733779907\n",
      "Epoch 5800, Loss: 1.6229902505874634\n",
      "Epoch 5900, Loss: 1.4660152196884155\n",
      "Epoch 6000, Loss: 1.3324143886566162\n",
      "Epoch 6100, Loss: 1.2179967164993286\n",
      "Epoch 6200, Loss: 1.1194918155670166\n",
      "Epoch 6300, Loss: 1.0341559648513794\n",
      "Epoch 6400, Loss: 0.9928882718086243\n",
      "Epoch 6500, Loss: 0.8983920216560364\n",
      "Epoch 6600, Loss: 0.8466106653213501\n",
      "Epoch 6700, Loss: 0.8027347326278687\n",
      "Epoch 6800, Loss: 0.7546418309211731\n",
      "Epoch 6900, Loss: 0.7334417700767517\n",
      "Epoch 7000, Loss: 0.6825835704803467\n",
      "Epoch 7100, Loss: 0.6489675641059875\n",
      "Epoch 7200, Loss: 0.6220866441726685\n",
      "Epoch 7300, Loss: 0.6498263478279114\n",
      "Epoch 7400, Loss: 0.5711175203323364\n",
      "Epoch 7500, Loss: 0.8529129028320312\n",
      "Epoch 7600, Loss: 0.5273359417915344\n",
      "Epoch 7700, Loss: 0.64078688621521\n",
      "Epoch 7800, Loss: 0.49182644486427307\n",
      "Epoch 7900, Loss: 0.47210636734962463\n",
      "Epoch 8000, Loss: 0.4599444270133972\n",
      "Epoch 8100, Loss: 0.4431491792201996\n",
      "Epoch 8200, Loss: 0.4288093149662018\n",
      "Epoch 8300, Loss: 0.9946262240409851\n",
      "Epoch 8400, Loss: 0.40324655175209045\n",
      "Epoch 8500, Loss: 0.38858431577682495\n",
      "Epoch 8600, Loss: 0.38121214509010315\n",
      "Epoch 8700, Loss: 0.36673393845558167\n",
      "Epoch 8800, Loss: 0.36485961079597473\n",
      "Epoch 8900, Loss: 0.34737059473991394\n",
      "Epoch 9000, Loss: 0.38353607058525085\n",
      "Epoch 9100, Loss: 0.3287191390991211\n",
      "Epoch 9200, Loss: 0.3266168236732483\n",
      "Epoch 9300, Loss: 0.3114875257015228\n",
      "Epoch 9400, Loss: 0.3073689043521881\n",
      "Epoch 9500, Loss: 0.2965150773525238\n",
      "Epoch 9600, Loss: 0.2958424687385559\n",
      "Epoch 9700, Loss: 0.282280832529068\n",
      "Epoch 9800, Loss: 0.28638625144958496\n",
      "Epoch 9900, Loss: 0.27008169889450073\n",
      "Predicted Viscosity for T=75, P=1.6: 132.30921936035156\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ANFIS(nn.Module):\n",
    "    def __init__(self, num_rules, input_dim):\n",
    "        super(ANFIS, self).__init__()\n",
    "        self.num_rules = num_rules\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # Gaussian membership function parameters\n",
    "        self.centers = nn.Parameter(torch.randn(num_rules, input_dim) * 10 + 50)  # Initialize around dataset range\n",
    "        self.sigmas = nn.Parameter(torch.ones(num_rules, input_dim) * 5)  # Reasonable initial sigma\n",
    "\n",
    "        # Linear rule parameters\n",
    "        self.p = nn.Parameter(torch.randn(num_rules))\n",
    "        self.q = nn.Parameter(torch.randn(num_rules))\n",
    "        self.r = nn.Parameter(torch.randn(num_rules))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Gaussian membership function\n",
    "        gaussian = torch.exp(-((x.unsqueeze(1) - self.centers) ** 2) / (2 * self.sigmas ** 2))\n",
    "        firing_strengths = gaussian.prod(dim=-1)  # Shape: (batch_size, num_rules)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        sum_firing = firing_strengths.sum(dim=1, keepdim=True)\n",
    "        sum_firing[sum_firing == 0] = 1.0  # Replace zero with 1.0 to prevent nan\n",
    "\n",
    "        # Normalize firing strengths\n",
    "        normalized_strengths = firing_strengths / sum_firing\n",
    "\n",
    "        # Compute rule outputs\n",
    "        rule_outputs = self.p * x[:, 0:1] + self.q * x[:, 1:2] + self.r  # Broadcasting\n",
    "\n",
    "        # Aggregate outputs\n",
    "        output = (normalized_strengths * rule_outputs).sum(dim=1)\n",
    "        return output\n",
    "\n",
    "# Dataset\n",
    "data = torch.tensor([\n",
    "    [50, 1.0],\n",
    "    [60, 1.2],\n",
    "    [70, 1.5],\n",
    "    [80, 1.7],\n",
    "    [90, 2.0],\n",
    "], dtype=torch.float32)\n",
    "targets = torch.tensor([120, 125, 130, 135, 140], dtype=torch.float32)\n",
    "\n",
    "# Initialize model\n",
    "model = ANFIS(num_rules=4, input_dim=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(data)\n",
    "    loss = criterion(predictions, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Example usage: Predict new data\n",
    "x_new = torch.tensor([[75.0, 1.6]], dtype=torch.float32)\n",
    "predicted_viscosity = model(x_new)\n",
    "print(f\"Predicted Viscosity for T=75, P=1.6: {predicted_viscosity.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
